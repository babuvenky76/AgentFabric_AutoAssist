# Application Configuration
APP_NAME=AutoAssist
DEBUG=false  # PRODUCTION: Always set to false
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR

# LLM Configuration
MODEL_PROVIDER=local  # Options: local, api
MODEL_NAME=mistral  # Your model name from LMStudio
API_ENDPOINT=http://localhost:1234/v1  # Use host.docker.internal for Docker
API_TOKEN=  # SECURITY: Never commit actual tokens to git
TEMPERATURE=0.7  # Range: 0.0-1.0
MAX_TOKENS=1024
TIMEOUT_SECONDS=30

# Service Configuration
SERVICE_PORT=8000
SERVICE_HOST=0.0.0.0

# Observability
ENABLE_METRICS=true
PROMETHEUS_PORT=9090

# Security (Optional - for production)
# GRAFANA_ADMIN_PASSWORD=your-strong-password-here
# RATE_LIMIT_PER_MINUTE=60
# ENABLE_AUTH=false
